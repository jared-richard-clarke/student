* Parsing for Compilers

*Introduction to Compilers and Language Design*, Douglas Thain

*Formal Languages* and *Set Theory*, Wikipedia

** Set Theory: Basic Concepts and Notation

- set :: Informally, a collection of unique objects: *{1, 2, 3}*.

- empty set :: For *Ø*, a unique set containing no elements: *{}*.

- disjoint sets :: Sets whose instersection is the empty set, meaning they have
  no elements in common.

- binary relation :: For *o ∈ A*, object *o* is a member of set *A*.
  
- subset :: For *A ⊆ B*, set *A* is a subset of set *B*.

- superset :: For *A ⊇ B*, set *A* is a superset of set *B*  
  
- proper subset :: For *A ⊂ B*, *A* is a subset of *B*, but *A* is not equal to *B*.

- proper superset :: For *A ⊃ B*, *A* is a superset of *B*, but *A* is not equal to *B*.
  
- union :: For *A ∪ B*, the set is members of *A* or *B* or both.
  
- intersection :: For *A ∩ B*, the set is members of both *A* and *B*.
  
- set difference :: For *A - B*, the set is members of *A* that are not members of *B*.
  
- symmetric difference :: For *A ⊖ B*, the set is members that are in one set, not both.
  
- cartesian product :: For *A × B*, the set whose members are all possible ordered pairs *(a, b)*,
  where *a ∈ A* and *b ∈ B*.

- power set :: For *P(A)*, the set whose members are all possible subsets of *A*.

** Formal Languages

In logic, mathematics, computer science, and linguistics, a formal language consists of words
whose letters are taken from an /alphabet/ and are /well-formed/ according to a specific set of rules
called a /formal grammar/.

Terminals and non-terminals are the lexical elements used in specifying the production rules
constituting a formal grammar. The terminals and non-terminals of a particular grammar are in
two completely separate sets.

*** Words over an Alphabet

- formal language :: *L* over an alphabet *Σ* is a subset of *Σ\star{}*, that is, a set of words
  over that alphabet.

- alphabet :: a *set*, whose members are called *letters*.
  
- word :: a finite sequence of letters who are members of an alphabet.
  
- Σ* :: The set of all words over an alphabet *Σ*.

-  Λ, e or ε :: For any alphabet, there is only one element of length zero. Combining a word with
  the empty word is the original word.

*** Degenerate Case

For finite languages, all well-formed words can be explicitly enumerated. The *degenerate* case
of this construction is the *empty language*, *L=Ø*, which contains no words at all.
  
*** A Classic Formalization of Generative Grammars

- A finite set *N* of non-terminal symbols.
  
- A finite set *Σ* of terminal symbols that is disjoint from *N*.
  
- A finite set of *P* of production rules, each rule of the form
  *(Σ ∪ N)\star{}N(Σ ∪ N)\star{} → (Σ ∪ N)\star{}*
  where *\star{}* is the Kleene star operator, denoting *concatenation*,
  and *∪* denotes *set union*.

- In the case that the body consists solely of an empty string, the body may be denoted with
  a special notation, usually *Λ*, *e* or *ε*.

- A distinguished symbol *S ∈ N* that is the start symbol.

*** Kleene Closure

1. If *V* is a set of strings, then *V\star{}* is defined as the smallest superset of *V* that
   contains the empty string *ε* and is closed under the string concatenation operation.

2. If *V* is a set of symbols or characters, then *V\star{}* is the set of all strings over symbols
   in *V*, including the empty string *ε*.

#+begin_example
V⁰   = {ε}
V¹   = V
Vⁿ⁺¹ = {wv : w ∈ Vⁿ and v ∈ V} for each n > 0 
#+end_example

Strings form a *monoid* with concatenation as the binary operation and *ε* the identity element.
The Kleene Closure is defined for any monoid, not just strings.

** Backus-Naur Form

In computer science, a *Backus-Naur form* or *Backus normal form* is a metasyntax notation
for context-free grammars. It is often used to describe the syntax of languages used in
computing, such as programming languages, document formats, instruction sets, and
communication protocols.

*** A BNF Specification

#+begin_example
<symbol> ::= expression
#+end_example

- <symbol> :: a non-terminal.
- ::= :: separates a rule from its productions.
- expression :: expression is one or more sequences of either terminal or non-terminal symbols
  where each sequence is separated by a vertical bar *|*, indicating choice.

** Context Free Grammars

Grammars in which the left-hand side of each production rule is always a single non-terminal.
The right-hand side of a rule is a sentential form that describes the allowable forms of the
corresponding non-terminal.

- terminal :: the elementary symbols of the language.
  
- non-terminal :: a language structure that can be replaced by sequences of terminal symbols.
  Also called syntactic variables. Includes declarations, statements, and expressions.

- sentence :: a valid sequence of terminals.
  
- sentential form :: a valid sequence of terminals and non-terminals.

- grammar :: a finite set of rules describing a valid set of strings.
  
- language :: the potentially infinite set of sentences described by a particular grammar.
  
- derivation :: a sequence of rule applications that prove a sentence is a member of a
  particular language.
  
- top-down derivation :: begin with the start symbol, applying rules to expand non-terminals
  until the desired sentenc is reached.
  
- bottom-up derivation :: begin at the desired sentence, applying rules backward until reaching
  the start symbol.

- weak equivalence :: two separate grammars that generate the same language.

- production :: a rewrite rule specifying symbol substitution to generate new symbol sequences.

** Example Grammar

This grammar is ambiguous because there are two possible derivations for any sentence involving
two plus signs.

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + E      |
| 3. E | identifier |
| 4. E | integer    |

For brevity, we occasionally condense a set of rules with a common left-hand side by combining all
the right-hand sides with a logical-or symbol:

#+begin_example
E -> E + E | identifier | integer
#+end_example

*** Top-Down Derivation

| sentential form                | apply rule        |
|--------------------------------+-------------------|
| P                              | P -> E            |
| E                              | E -> E + E        |
| E + E                          | E -> identitifier |
| identifier + E                 | E -> E + E        |
| identifier + E + E             | E -> integer      |
| identifier + integer + E       | E -> integer      |
| identifier + integer + integer |                   |

*** Bottom-Up Derivation

| sentential form                | apply rule      |
|--------------------------------+-----------------|
| identifier + integer + integer | E -> integer    |
| identifier + integer + E       | E -> integer    |
| identifier + E + E             | E -> E + E      |
| identifier + E                 | E -> identifier |
| E + E                          | E -> E + E      |
| E                              | P -> E          |
| p                              |                 |

** Ambiguous Grammars

~identifier + integer + integer~ is ambiguous because it has two possible derivations.

*** Left-Most Derivation

#+begin_example
        P
        |
        E
	|
      E + E
      /   \
   E + E  int
   /   \
ident  int
#+end_example

*** Right-Most Derivation

#+begin_example
      P
      |
      E
      |
    E + E
    /   \
ident  E + E
       /   \
     int   int       
#+end_example

*** Removing Ambiguity

It is possible to re-write a grammar so that it is not ambiguous. With binary operators, we can require
one side of an expression to be an atomic term (*T*). The grammar below is no longer ambiguous, because
it only allows a left-most derivation.

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + T      |
| 3. E | T          |
| 4. T | identifier |
| 5. T | integer    |

Further modification to the grammar is required to account for multiple levels of precedence. The usual
approach is to construct a grammar with multiple levels, each reflecting the intended precedence of
operators. Addition combined with multiplication can be expressed as the sum of terms (*T*) that consist
of multiplied factors (*F*).

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + T      |
| 3. E | T          |
| 4. T | T * F      |
| 5. T | F          |
| 6. F | identifier |
| 7. F | integer    |

#+begin_example
=== ambiguous ===

E -> E + E | E * E | (E) | number

=== unambiguous ===

E -> T | E + T
T -> F | T * F
F -> number | (E)
#+end_example

** LL(1) Grammars

*LL* parsers (left-to-right, left-most derivation) is a top-down parser for a restricted
context-free language. An *LL* parser is called an *LL(k)* parser if it uses *k* tokens
of lookahead when parsing a sentence.

*LL(1)* grammars are a subset of CFGs that can be parsed by considering only one non-terminal and
the next token in the input stream. To make a grammar *LL(1)* we must do the following:

1. Remove ambiguous derivations.
2. Eliminate left recursion.
3. Eliminate any common left prefixes through left factoring.
4. Formally prove the grammar is *LL(1)* by generating FIRST and FOLLOW sets for the grammar.

*** Eliminating Left Recursion

*LL(1)* grammars cannot contain left recursion. The expression *E -> E + T* is left-recursive because *E*
appears as the first symbol on the right-hand side. Thus *E -> E + T* would expand to *(E + T) + T*,
which would expand into *((E + T) + T) + T* and so on into infinity.

Rewriting the rule as *E -> T + E* would remove left recursion, but it creates a right-associative
operation and a common left prefix. Instead the rules must be rewritten so that the formally recursive
rule begins with the leading symbols of its alternatives.

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | T E'       |
| 3. E' | + T E'     |
| 4. E' | ε          |
| 5. T  | identifier |
| 6. T  | integer    |

Left recursion is primarily a theoretical problem. Looping constructs, or iteration, are excellent
real-world solutions.

Parsing expressions with precedence requires unintuitive rewritings of context-free grammars.
It is simpler to either loop through a list of atoms separated by operators and reconstruct the
tree separately or fuse the two stages into a recursive loop — a Pratt parser.

#+begin_src c
  Program parse_statements() {
    for(;;) {
      parse_statement();
      if (next() != SEMI_COLON) {
	break;
      }
    }
  }
#+end_src
   
*** Eliminating Common Left Prefixes

Look for all common prefixes of a given non-terminal and replace them with one rule that contains
the prefix and another that contains the variants. This process is called /left factorization/,
which eliminates backtracking and redundant parsings.

**** Before Left Factoring

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | id         |
| 3. E | id[E]      |
| 4. E | id(E)      |

**** After Left Factoring

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | id E'      |
| 3. E' | [E]        |
| 4. E' | (E)        |
| 5. E' | ε          |

** First and Follow Sets

In order to construct a complete parser for an *LL(1)* grammar, we must compute two sets, known as
*FIRST* and *FOLLOW*.

*** Computing First Sets for a Grammar *G*

#+begin_example
FIRST(α) is the set of terminals that begin all strings given by α,
including  ε if α ⇒  ε.

For Terminals:
For each terminal a ∈ Σ: FIRST(a) = {a}

For Non-Terminals:
Repeat:
    For each rule X -> Y1Y2...Yk in a grammar G:
        Add a to FIRST(X)
	    if a is in FIRST(Y1)
	    or a is in FIRST(Yn) and Y1...Yn-1 ⇒ ε
	If Y1...Yk ⇒ ε then add ε to FIRST(X)
until no more changes occur.

For a Sentential Form α:
For each symbol Y1Y2...Yk in α:
    Add a to FIRST(α)
        if a is in FIRST(Y1)
	or a is in FIRST(Yn) and Y1...Yn-1 ⇒ ε
    If Y1...Yk ⇒ ε then add ε to FIRST(α).
#+end_example

*** Computing Follow Sets for Grammar *G*

#+begin_example
FOLLOW(A) is the set of terminals that can come after
non-terminal A, including $ if A occurs at the end of the input.

FOLLOW(S) = {$} where S is the start symbol.

Repeat:
    If A -> αBβ then:
        add FIRST(β) (excepting ε) to FOLLOW(B).
    If A -> αB or FIRST(β) contains ε then:
        add FOLLOW(A) to FOLLOW(B).
until no more changes occur.
#+end_example

*** Grammar Translated By First and Follow

**** Grammmar

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | T E'       |
| 3. E' | + T E'     |
| 4. E' | ε          |
| 5. T  | F T'       |
| 6. T' | * F T'     |
| 7. T' | ε          |
| 8. F  | (E)        |
| 9. F  | integer    |

**** First and Follow

|        | P            | E            | E'     | T            | T'        | F            |
| FIRST  | {(, integer} | {(, integer} | {+, ε} | {(, integer} | {*, ε}    | {(, integer} |
| FOLLOW | {$}          | {), $}       | {), $} | {+, ), $}    | {+, ), $} | {+, *, ), $} |

** Recursive Descent Parsing

*LL(1)* grammars are amenable to /recursive descent parsing/ in which there is one function for each
non-terminal in a grammar. The body of each function follows the right-hand sides of the corresponding
rules: non-terminals result in a call to another parse function, while terminals result in considering
the next token.

Two special cases must be considered:

1. If rule *X* cannot produce *ε* and the token is not in *FIRST(X)*, then return error.
2. If rule *X* could produce *ε* and the token is not in *FIRST(X)*, return success.
   Another rule will consume that token.

Three helper functions are needed:

- ~next()~ :: returns the next token in the input stream.
- ~peek()~ :: looks ahead to the next token without the parser consuming it.
- ~match(t)~ :: consumes the next token if it matches ~t~.

*** Grammar Translated into a Recursive Descent Parser

#+begin_src c
  int parse_P() {
    return parse_E() && match(TOKEN_EOF);
  }

  int parse_E() {
    return parse_T() && parse_E_prime();
  }

  int parse_E_prime() {
    token_t t = peek();
    if (t == TOKEN_PLUS) {
      next();
      return parse_T() && parse_E_prime();
    }
    return 1;
  }

  int parse_T() {
    return parse_F() && parse_T_prime();
  }

  int parse_T_prime() {
    token_t t = peek();
    if (t == TOKEN_MULTIPLY) {
      next();
      return parse_F() && parse_T_prime();
    }
    return 1;
  }

  int parse_F() {
    token_t t = peek();
    if (t == TOKEN_LPAREN) {
      next();
      return parse_E() && match(TOKEN_RPAREN);
    } else if (t == TOKEN_INT) {
      next();
      return 1;
    } else {
      printf("parse error: unexpected token %s\n", token_string(t));
      return 0;
    }
  }
#+end_src

** LR Grammars

*LR* parsers (left-to-right, rightmost derivation in reverse) are a type of bottom-up parser that
analyze deterministic context-free languages in linear time, meaning they read input text from
left to right without backing up, producing a right-most derivation from the bottom up.

An *LR* parser scans and parses the input text in one forward pass over the text. The parser builds
up the parse tree incrementally, bottom up, and left to right, without guessing or backtracking.
At every point in this pass, the parser has accumulated a list of subtrees or phrases of the input
text that have been already parsed. Those subtrees are not yet joined together because the parser
has not yet reached the right end of the syntax pattern that will combine them. 

*** Shift-Reduce Parsing

#+begin_example
=== expression ===
A * 2 + 1

=== derivation ===
                              13 Sums
             -----------------
            /           /     |
           8 Sums      |      |
           |           |      |
   7 Products          |      |
 /         | \         |      |
3 Products |  \        |      12 Products
|          |   |       |      |
2 Value    |   6 Value |      11 Value
|          |   |       |      |
1 id       4   5 int   9      10 int
|          |   |       |      |
A          *   2       +      1

=== parser at step 6 ===
                                  --------
                                 | table  |
                                 |--------|
               /---------------- | loop   |
	      /                   --------
 stack       /                      |
|----------------------------|      |
 ----------------------------       |
| Products | * | Value | ... |      |   
 ----------------------------     lookahead
  |          |     |                |
 ---        ---   ---              -------
| A |      | * | | 2 |            | + | 1 | - unscanned
 ---        ---   ---              -------
|-----------------------------------------|
 input stream
#+end_example

| step | stack            | lookahead | unscanned | action | grammar rule                |
|------+------------------+-----------+-----------+--------+-----------------------------|
|    0 | empty            | id        | * 2 + 1   | shift  |                             |
|    1 | id               | *         | 2 + 1     | reduce | Value → id                  |
|    2 | Value            | *         | 2 + 1     | reduce | Products → Value            |
|    3 | Products         | *         | 2 + 1     | shift  |                             |
|    4 | Products *       | int       | + 1       | shift  |                             |
|    5 | Products * int   | +         | 1         | reduce | Value → int                 |
|    6 | Products * Value | +         | 1         | reduce | Products → Products * Value |
|    7 | Products         | +         | 1         | shift  | Sum → Products              |
|    8 | Sums             | +         | 1         | shift  |                             |
|    9 | Sums +           | int       | eof       | shift  |                             |
|   10 | Sums + int       | eof       |           | reduce | Value → int                 |
|   11 | Sums + Value     | eof       |           | reduce | Products → Value            |
|   12 | Sums + Products  | eof       |           | reduce | Sums → Sums + Products      |
|   13 | Sums             | eof       |           | accept |                             |

*** LR(1) Parsing

An *LR(1)* grammar can be parsed via shift-reduce with a single token of lookahead.

- Shift :: consumes one token from the input stream and pushes it onto the stack.
  This becomes a new single-node parse tree.
- Reduce :: applies a completed grammar rule to some of the recent parse trees, joining them
  together as one tree with a new root symbol.

Each action is chosen by traversing a graph where each node is a state within a finite state machine.
The state machine tells us the available actions at each step. Each state in the machine consists
of multiple items, which are rules augmented by a *dot(.)* that indicates the parsers current position
in that rule.

The machine tells us the choices available at any step of bottom-up parsing. When a state containing an
item with a dot at the end of a rule is reached, that indicates a possible reduction. A transition on a
terminal that moves the dot one position to the right indicates a possible shift.

*SLR* parsing is a basic form of *LR* parsing where *FOLLOW* sets are used to resolve shift-reduce
conflicts. For example, reduction *A -> α* is only applied when the next token on the input is in
*FOLLOW(A)*. These decisions are encoded in *parse tables*, historically known as *GOTO* and *ACTION*.
To be *SLR*, each state in the table can be occupied by only one action.

** Grammar Classes

#+begin_example
LL(1) ⊂ SLR ⊂ LALR ⊂ LR(1) ⊂ CFG
#+end_example

- Context-Free Grammar :: Any grammar whose rules have the form *A -> α*. Requires a parse
  table and a stack to track parser state. An ambiguous CFG creates a non-deterministic finite
  automaton.

- LR(k) :: Performs bottom-up, left-right scan and right-most parse of the input, deciding what rule
  to apply next by examining the next *k* tokens. Requires a very large automaton, because the possible
  lookaheads are encoded into states.

- LALR :: A /Lookahead-LR/ parser created by constructing an *LR(1)* parser then merging all item sets
  that have the same core.

- SLR :: A /Simple-LR/ parser approximates an *LR(1)* parser by constructing an *LR(0)* state machine
  and then relying on the *FIRST* and *FOLLOW* sets to select which rule to apply.

- LL(k) :: Performs a top-down, left-right scan and left-most parse of the input, deciding what items
  to rule to apply next by examining the next *k* tokens. *LL(1)* parsers require a only table that
  is *O(nt)* where *t* is the number of tokens and *n* is the number of non-terminals.

** The Chomsky Hierarchy

| language class         | machine required        |
|------------------------+-------------------------|
| regular                | finite automata         |
| context free           | pushdown automata       |
| context sensitive      | linear bounded automata |
| recursively enumerable | Turing machine          |

- Regular Languages :: Languages described by regular expressions. Every regular expression corresponds
  to a finite automaton that can be implemented with a table and a single integer to represent the
  current state.

- Context Free Languages :: The meaning of a non-terminal is the same in all places where it appears.
  CFGs require pushdown automaton, which requires a finite automaton coupled with a stack. If the
  grammar is ambiguous, the automaton will be non-deterministic and therefore impractical.

- Context Sensitive Languages :: The meaning of a non-terminal is controlled by the context in which it
  appears. CSLs require a non-deterministic linear bounded automaton, which is bounded in memory
  consumption but not in execution time.

- Recursively Enumerable Languages :: The least restrictive set of languages, described by the rules
  *α -> β* where *α* and *β* can be any combination of terminals and non-terminals. These languages
  can only be recognized by a full Turing machine.

** General Principle of Language Design

#+begin_quote
The least powerful language gives the strongest guarantees.

— Douglas Thain
#+end_quote
