* Parsing for Compilers

*Introduction to Compilers and Language Design*, Douglas Thain

*Formal Languages* and *Set Theory*, Wikipedia

** Set Theory: Basic Concepts and Notation

- set :: Informally, a collection of unique objects: *{1, 2, 3}*.

- empty set :: For *Ø*, a unique set containing no elements: *{}*.

- disjoint sets :: Sets whose instersection is the empty set, meaning they have
  no elements in common.

- binary relation :: For *o ∈ A*, object *o* is a member of set *A*.
  
- subset :: For *A ⊆ B*, set *A* is a subset of set *B*.

- superset :: For *A ⊇ B*, set *A* is a superset of set *B*  
  
- proper subset :: For *A ⊂ B*, *A* is a subset of *B*, but *A* is not equal to *B*.

- proper superset :: For *A ⊃ B*, *A* is a superset of *B*, but *A* is not equal to *B*.
  
- union :: For *A ∪ B*, the set is members of *A* or *B* or both.
  
- intersection :: For *A ∩ B*, the set is members of both *A* and *B*.
  
- set difference :: For *A - B*, the set is members of *A* that are not members of *B*.
  
- symmetric difference :: For *A ⊖ B*, the set is members that are in one set, not both.
  
- cartesian product :: For *A × B*, the set whose members are all possible ordered pairs *(a, b)*,
  where *a ∈ A* and *b ∈ B*.

- power set :: For *P(A)*, the set whose members are all possible subsets of *A*.

** Formal Languages

In logic, mathematics, computer science, and linguistics, a formal language consists of words
whose letters are taken from an /alphabet/ and are /well-formed/ according to a specific set of rules
called a /formal grammar/.

Terminals and non-terminals are the lexical elements used in specifying the production rules
constituting a formal grammar. The terminals and non-terminals of a particular grammar are in
two completely separate sets.

*** Words over an Alphabet

- formal language :: *L* over an alphabet *Σ* is a subset of *Σ\star{}*, that is, a set of words
  over that alphabet.

- alphabet :: a *set*, whose members are called *letters*.
  
- word :: a finite sequence of letters who are members of an alphabet.
  
- Σ* :: The set of all words over an alphabet *Σ*.

-  Λ, e or ε :: For any alphabet, there is only one element of length zero. Combining a word with
  the empty word is the original word.

*** Degenerate Case

For finite languages, all well-formed words can be explicitly enumerated. The *degenerate* case
of this construction is the *empty language*, *L=Ø*, which contains no words at all.
  
*** A Classic Formalization of Generative Grammars

- A finite set *N* of non-terminal symbols.
  
- A finite set *Σ* of terminal symbols that is disjoint from *N*.
  
- A finite set of *P* of production rules, each rule of the form
  *(Σ ∪ N)\star{}N(Σ ∪ N)\star{} → (Σ ∪ N)\star{}*
  where *\star{}* is the Kleene star operator, denoting *concatenation*,
  and *∪* denotes *set union*.

- In the case that the body consists solely of an empty string, the body may be denoted with
  a special notation, usually *Λ*, *e* or *ε*.

- A distinguished symbol *S ∈ N* that is the start symbol.

*** Kleene Closure

1. If *V* is a set of strings, then *V\star{}* is defined as the smallest superset of *V* that
   contains the empty string *ε* and is closed under the string concatenation operation.

2. If *V* is a set of symbols or characters, then *V\star{}* is the set of all strings over symbols
   in *V*, including the empty string *ε*.

#+begin_example
V⁰   = {ε}
V¹   = V
Vⁿ⁺¹ = {wv : w ∈ Vⁿ and v ∈ V} for each n > 0 
#+end_example

Strings form a *monoid* with concatenation as the binary operation and *ε* the identity element.
The Kleene Closure is defined for any monoid, not just strings.

** Backus-Naur Form

In computer science, a *Backus-Naur form* or *Backus normal form* is a metasyntax notation
for context-free grammars. It is often used to describe the syntax of languages used in
computing, such as programming languages, document formats, instruction sets, and
communication protocols.

*** A BNF Specification

#+begin_example
<symbol> ::= expression
#+end_example

- <symbol> :: a non-terminal.
- ::= :: separates a rule from its productions.
- expression :: expression is one or more sequences of either terminal or non-terminal symbols
  where each sequence is separated by a vertical bar *|*, indicating choice.

** Context Free Grammars

Grammars in which the left-hand side of each production rule is always a single non-terminal.
The right-hand side of a rule is a sentential form that describes the allowable forms of the
corresponding non-terminal.

- terminal :: The elementary symbols of a language.

- non-terminal :: A language structure that can be replaced by sequences of terminal symbols.
  Also called syntactic variables.

- sentence :: A valid sequence of terminals.

- sentential form :: A valid sequence of terminals and non-terminals.

- grammar :: A finite set of rules describing a valid set of sentences.

- language :: The potentially infinite set of sentences described or set of strings generated
  by a particular grammar.

- start symbol :: The special, non-terminal symbol representing the top-level definition
  of a program.

- derivation :: A sequence of rule applications that prove a sentence is a member of a
  particular language.

- (⇒) :: Shows that one sentential form is equal to another by applying a given rule.

- top-down derivation :: Begins with the start symbol, applying rules to expand non-terminals
  until the desired sentence is reached.

- bottom-up derivation :: Begins at the desired sentence, applying rules backward until reaching
  the start symbol.

- weak equivalence :: Two separate grammars that generate the same language.

- production :: A rewrite rule specifying symbol substitution to generate new symbol sequences.

*** Derivation

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + E      |
| 3. E | identifier |
| 4. E | integer    |

For brevity, we occasionally condense a set of rules with a common left-hand side by combining all
the right-hand sides with a logical-or symbol:

#+begin_example
E → E + E | identifier | integer
#+end_example

*** Top-Down Derivation

| sentential form                | apply rule       |
|--------------------------------+------------------|
| P                              | P → E            |
| E                              | E → E + E        |
| E + E                          | E → identitifier |
| identifier + E                 | E → E + E        |
| identifier + E + E             | E → integer      |
| identifier + integer + E       | E → integer      |
| identifier + integer + integer |                  |

*** Bottom-Up Derivation

| sentential form                | apply rule     |
|--------------------------------+----------------|
| identifier + integer + integer | E → integer    |
| identifier + integer + E       | E → integer    |
| identifier + E + E             | E → E + E      |
| identifier + E                 | E → identifier |
| E + E                          | E → E + E      |
| E                              | P → E          |
| P                              |                |

*** Ambiguity

~identifier + integer + integer~ for the grammar above is ambiguous because it has two possible derivations.

**** Left-Most Derivation

#+begin_example
        P
        |
        E
	|
      E + E
      /   \
   E + E  int
   /   \
ident  int
#+end_example

**** Right-Most Derivation

#+begin_example
      P
      |
      E
      |
    E + E
    /   \
ident  E + E
       /   \
     int   int       
#+end_example

*** Removing Ambiguity

It is possible to re-write a grammar so that it is not ambiguous. With binary operators, we can require
one side of an expression to be an atomic term (*T*). The grammar below is no longer ambiguous, because
it allows only a left-most derivation.

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + T      |
| 3. E | T          |
| 4. T | identifier |
| 5. T | integer    |

Further modification to the grammar is required to account for multiple levels of precedence. The usual
approach is to construct a grammar with multiple levels, each reflecting the intended precedence of
operators. Addition combined with multiplication can be expressed as the sum of terms (*T*) that consist
of multiplied factors (*F*).

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | E + T      |
| 3. E | T          |
| 4. T | T * F      |
| 5. T | F          |
| 6. F | identifier |
| 7. F | integer    |

#+begin_example
=== ambiguous ===

E → E + E | E * E | (E) | number

=== unambiguous ===

E → T | E + T
T → F | T * F
F → number | (E)
#+end_example

** LL Grammars and Parsing

*** Notation

The notation used in these notes is the notation used by Douglas Thain in his book *ICLD*.

- Lowercase letters represent terminals: keywords, operators, identifiers, etc.
- Uppercase letters represent non-terminals: *P*, *S*, *E*, etc.
- Greek letters represent sentential forms — potentially mixed sequences of terminals and non-terminals:
  *α*, *β*, *γ*, etc.

- Sequences represent individual symbols in a sentential form: *Y_{1}Y_{2}...Y_{n}* where *Y_{i}* may
  be either a terminal or non-terminal.

*** Actions

- L :: left-to-right parsing

- L :: left-most derivation

- (k) :: k-symbol lookahead

*** LL(1)

*LL* parsers are top-down parsers for restricted context-free languages. An *LL* parser is called an
*LL(k)* parser if it uses *k* tokens of lookahead when parsing a sentence.

*LL(1)* grammars are a subset of CFGs that can be parsed by considering only one non-terminal and
the next token in the input stream. To make a grammar *LL(1)* we must do the following:

1. Remove ambiguous derivations.
2. Eliminate left recursion.
3. Eliminate any common left prefixes through left factoring.
4. Formally prove the grammar is *LL(1)* by generating *FIRST* and *FOLLOW* sets for the grammar.

*** Eliminating Left Recursion

*Left Recursion*: *A → Bβ* such that *B ⇒ Aγ*.

*LL(1)* grammars cannot contain left recursion. The expression *E → E + T* is left-recursive because *E*
appears as the first symbol on the right-hand side. Thus *E → E + T* would expand to *(E + T) + T*,
which would expand into *((E + T) + T) + T* and so on into infinity.

Rewriting the rule as *E → T + E* would remove left recursion, but it creates a right-associative
operation and a common left prefix. Instead the rules must be rewritten so that the formally recursive
rule begins with the leading symbols of its alternatives.

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | T E'       |
| 3. E' | + T E'     |
| 4. E' | ε          |
| 5. T  | identifier |
| 6. T  | integer    |

#+begin_example
P  ::= E
E  ::= T E'
E' ::= + T E'
     | ε
T  ::= identifier
     | integer
#+end_example

Left recursion is primarily a theoretical problem. Looping constructs, or iteration, are excellent
real-world solutions.

Parsing expressions with precedence requires unintuitive rewritings of context-free grammars.
It is simpler to either loop through a list of atoms separated by operators and reconstruct the
tree separately or fuse the two stages into a recursive loop — a Pratt parser.

#+begin_src c
  Program parse_statements() {
    for(;;) {
      parse_statement();
      if (next() != SEMI_COLON) {
        break;
      }
    }
  }
#+end_src

*** Eliminating Common Left Prefixes

Look for all common prefixes of a given non-terminal and replace them with one rule that contains
the prefix and another that contains the variants. This process is called /left factorization/,
which eliminates backtracking and redundant parsings.

**** Before Left Factoring

| rule | production |
|------+------------|
| 1. P | E          |
| 2. E | id         |
| 3. E | id[E]      |
| 4. E | id(E)      |

#+begin_example
P ::= E
E ::= id
    | id[E]
    | id(E)
#+end_example

**** After Left Factoring

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | id E'      |
| 3. E' | [E]        |
| 4. E' | (E)        |
| 5. E' | ε          |

#+begin_example
P  ::= E
E  ::= id E'
E' ::= [E]
     | (E)
     | ε
#+end_example

*** First and Follow Sets

In order to construct a complete parser for an *LL(1)* grammar, we must compute two sets, known as
*FIRST* and *FOLLOW*.

**** Computing First Sets for a Grammar *G*

#+begin_example
FIRST(α) is the set of terminals that begin all strings given by α,
including  ε if α ⇒ ε.

For Terminals:
For each terminal a ∈ Σ: FIRST(a) = {a}

For Non-Terminals:
Repeat:
    For each rule X → Y1Y2...Yk in a grammar G:
        Add a to FIRST(X)
            if a is in FIRST(Y1)
            or a is in FIRST(Yn) and Y1...Yn-1 ⇒ ε
        If Y1...Yk ⇒ ε then add ε to FIRST(X)
until no more changes occur.

For a Sentential Form α:
For each symbol Y1Y2...Yk in α:
    Add a to FIRST(α)
        if a is in FIRST(Y1)
        or a is in FIRST(Yn) and Y1...Yn-1 ⇒ ε
    If Y1...Yk ⇒ ε then add ε to FIRST(α).
#+end_example

**** Computing Follow Sets for Grammar *G*

#+begin_example
FOLLOW(A) is the set of terminals that can come after
non-terminal A, including $ if A occurs at the end of the input.

FOLLOW(S) = {$} where S is the start symbol.

Repeat:
    If A → αBβ then:
        add FIRST(β) (excepting ε) to FOLLOW(B).
    If A → αB or FIRST(β) contains ε then:
        add FOLLOW(A) to FOLLOW(B).
until no more changes occur.
#+end_example

*** Grammar Translated By First and Follow

**** Grammmar

| rule  | production |
|-------+------------|
| 1. P  | E          |
| 2. E  | T E'       |
| 3. E' | + T E'     |
| 4. E' | ε          |
| 5. T  | F T'       |
| 6. T' | * F T'     |
| 7. T' | ε          |
| 8. F  | (E)        |
| 9. F  | integer    |

#+begin_example
P  ::= E
E  ::= T E'
E' ::= + T E'
     | ε
T  ::= F T'
T' ::= * F T'
     | ε
F  ::= (E)
     | integer
#+end_example

**** First and Follow

|        | P            | E            | E'     | T            | T'        | F            |
| FIRST  | {(, integer} | {(, integer} | {+, ε} | {(, integer} | {*, ε}    | {(, integer} |
| FOLLOW | {$}          | {), $}       | {), $} | {+, ), $}    | {+, ), $} | {+, *, ), $} |

** Recursive Descent Parsing

*LL(1)* grammars are amenable to /recursive descent parsing/ in which there is one function for each
non-terminal in a grammar. The body of each function follows the right-hand sides of the corresponding
rules: non-terminals result in a call to another parse function, while terminals result in considering
the next token.

Two special cases must be considered:

1. If rule *X* cannot produce *ε* and the token is not in *FIRST(X)*, then return error.
2. If rule *X* could produce *ε* and the token is not in *FIRST(X)*, return success.
   Another rule will consume that token.

Three helper functions are needed:

- ~next()~ :: returns the next token in the input stream.
- ~peek()~ :: looks ahead to the next token without the parser consuming it.
- ~match(t)~ :: consumes the next token if it matches ~t~.

*** Grammar Translated into a Recursive Descent Parser

This C program serves only to verify that the input program matches the grammar outlined above.

#+begin_src c
  // P ::= E $
  int parse_P() {
    return parse_E() && match(TOKEN_EOF);
  }
  // E ::= T E'
  int parse_E() {
    return parse_T() && parse_E_prime();
  }
  // E' ::= + T E' | ε 
  int parse_E_prime() {
    token_t t = peek();
    if (t == TOKEN_PLUS) {
      next();
      return parse_T() && parse_E_prime();
    }
    return 1;
  }
  // T ::= F T'
  int parse_T() {
    return parse_F() && parse_T_prime();
  }
  // T' ::= * F T' | ε
  int parse_T_prime() {
    token_t t = peek();
    if (t == TOKEN_MULTIPLY) {
      next();
      return parse_F() && parse_T_prime();
    }
    return 1;
  }
  // F ::= (E) | integer
  int parse_F() {
    token_t t = peek();
    if (t == TOKEN_LPAREN) {
      next();
      return parse_E() && match(TOKEN_RPAREN);
    } else if (t == TOKEN_INT) {
      next();
      return 1;
    } else {
      printf("parse error: unexpected token %s\n", token_string(t));
      return 0;
    }
  }
#+end_src

** LR Grammars and Parsing

*** Actions

- L :: left-to-right parse
  
- R :: Right-most derivation. Expands the right-most nonterminal. Reductions in reverse order,
  from the leaves to the root.
  
- (k) :: k-symbol lookahead.

An *LR(k)* parser has a stack and input. Given the contents of a stack and *k* tokens
of lookahead, the parser does one of the following operations:

1. *shift (SHIFT)*: Push the current input symbol onto the stack. Scan the next symbol.
  
2. *reduce (REDUCE)*: A grammar rule's right-hand side is on top of the stack. Pop the symbols
   and replace them with the grammar rule's left-hand-side nonterminal.

3. *accept (STOP)*: The parser has reached the end of the input without error, where the state
   at the top of the stack and the lookahead terminal symbol is within the subject grammar and
   represents the end of a program.

4. *reject (ERROR)*: The input is syntactically incorrect, where the state at the top of the
   stack and the lookahead symbol is not within the subject grammar.

The difference between *SLR*, *LALR*, and *LR* parsers is in the tables that they use. Different tables
use different techniques to determine when to *reduce*, and, if there is more than one grammar rule with
the same right-hand side, which left-hand-side nonterminal to push.

*** Choices

*LR(k)* parsers use *deterministic finite automata (DFAs)* to choose when to shift or reduce. The symbols
pushed onto the parser's stack are not actually terminals and nonterminals. They are *states* within
a finite state machine.

- At each step, the parser runs a *DFA* using symbols on the stack as input. The input
  is a sequence of terminals and nonterminals from the bottom up.

- The current state of the *DFA* plus the next *k* tokens of the input indicate whether to shift or reduce.

- The states of a *DFA* are sets of *items*.
  - An item is a production with a *marker(.)* indicating the current position of the parser.
  - In general, item *X → γ . δ* means *γ* is at the top of the stack. At the head of the input
    there is a string derivable from *δ*

*LR* parsers use two tables: the *action* table and the *goto* table.

- action table :: Indexed by the top-of-the-stack symbol and the current token. Tells which of the four
  actions — shift, reduce, accept, reject — to perform.

- goto table :: If a rule contains *n* symbols, we pop *n* states off the stack. The *goto table* is indexed
  by state symbol *t* and nonterminal *A*, where *t* is the state symbol on the top of the stack after
  popping *n* times

*** Algorithm

All *LR* parsers use this same basic algorithm. The states that are pushed onto the stack represent the states
in the underlying finite state machine. Each place we might be in the input is represented within the state as
an *item*.

The differences between *LR* parsers:

- The definition of an item.
- The number of states within the underlying finite state machine.
- The amount of information within the state.

#+begin_example
# === main loop: pseudo code ===

push initial state s0
a = scan()
loop
    t = top-of-stack (state) symbol
    switch action[t, a] {
       case shift s:
           push(s)
           a = scan()
       case reduce by A → alpha:
           for i = 1 to length(alpha) do pop() end
	   t = top-of-stack symbol
           push(goto[t, A])
       case accept:
           return( SUCCESS )
       case error:
           call the error handler
           return( FAILURE )
    }
end
#+end_example
  
*** LR(0) Automaton

**** Grammar

| rule | production |
|------+------------|
| S'   | S $        |
| S    | ( L )      |
| S    | x          |
| L    | S          |
| L    | L, S       |

**** Automaton

#+begin_example
1.
 -------------        2.             8.                  9.
| S' → .S $   |  x    --------   x   ------------    S   ----------
| S  → .(L)   |----->| S → x. |<----| L → L,.S   |----->| L → L,S. |
| S  → .x     |-+     --------      | S → .( L ) |       ----------
 -------------  |    3.             | S → .x     |
     S |      ( |     ------------   ------------
4.     V        +--->| S → (.L )  | ( |     ^
 ------------        | L → .S     |<--+     | ,
| S' → S.$   |       | L → .L, S  |         |       5.
 ------------        | S → .( L ) |  L    -----------
                     | S → .x     |----->| S → ( L.) |
                      ------------       | L → L.,S  |
                          |               -----------
                        S |                 |
                          V   7.            | )
                       --------             V        6.
                      | L → S. |          ------------
                       --------          | S → ( L ). |
                                          ------------
#+end_example

**** Action Table

1. Build action table.
2. If state contains item *X → γ.$* then *accept*.
3. If state contains item *X → γ.* then *reduce* *X → γ*.
4. If state *i* has edge to *j* with terminal, then *shift*.

| state | action           |
|-------+------------------|
|     1 | shift            |
|     2 | reduce S → x     |
|     3 | shift            |
|     4 | accept           |
|     5 | shift            |
|     6 | reduce S → ( L ) |
|     7 | reduce L → S     |
|     8 | shift            |
|     9 | reduce L → L, S  |

*** LR(1) Parsing

In practice, *LR(1)* is used for *LR* parsing.

- Item is now pair *(X → γ.δ, x)*
  - *γ* is at the top of the stack, and at the head of the input there is a string derivable
    from *δx* (where *x* is the terminal).
  - Algorithm for constructing state transition table and action table adapted.
    - Closure operation when constructing states uses *FIRST()*, incorporating lookahead token.
    - Action table columns now terminals.
    - State transition relation and action table typically combined into a single table,
      *GOTO and ACTION*.

*** Shift-Reduce Parsing Example

**** LR(1) Grammar

| rule | production  |
|------+-------------|
|    0 | P → E $     |
|    1 | E → T E'    |
|    2 | E' → + T E' |
|    3 | E' → ε      |
|    4 | T → 1       |

**** FIRST Table

| non-terminal | first  |
|--------------+--------|
| P            | {1}    |
| E            | {1}    |
| E'           | {+, ε} |
| T            | {1}    |

**** LR(1) Closure Table

| goto        | kernel                 | state | closure                                                  |
|-------------+------------------------+-------+----------------------------------------------------------|
|             | [ P → .E, $ ]          |     0 | [ P → .E, $ ], [ E → .T E', $ ], [ T → .1, +/$ ]         |
| goto(0, E)  | [ P → E., $ ]          |     1 | [ P → E., $ ]                                            |
| goto(0, T)  | [ E → T.E', $ ]        |     2 | [ E → T.E', $ ], [ E' → .+ T E', $ ], [ E' → ., $ ]      |
| goto(0, 1)  | [ T → 1., +/$ ]        |     3 | [ T → 1., +/$ ]                                          |
| goto(2, E') | [ E → T E' ., $ ]      |     4 | [ E → T E'., $ ]                                         |
| goto(2, +)  | [ E' → +.T E', $ ]     |     5 | [ E' → +.T E', $ ], [ T → .1, +/$ ]                      |
| goto(5, T)  | [ E' → + T.E', $ ]     |     6 | [ E' → + T.E', $ ], [ E' → .+ T E', $ ], [ E' → ., $ ]   |
| goto(5, 1)  | [ T → 1., +/$ ]        |     3 |                                                          |
| goto(6, E') | [ E' → + T E' ., $ ]   |     7 | [ E' → + T E' ., $ ]                                     |
| goto(6, +)  | [ E' → +.T E', $ ]     |     5 |                                                          |

**** LR Table: Action and Goto

| state | +  | 1  | $      | P | E | E' | T |
|-------+----+----+--------+---+---+----+---|
|     0 |    | s3 |        |   | 1 |    | 2 |
|     1 |    |    | accept |   |   |    |   |
|     2 | s5 |    | r3     |   |   |  4 |   |
|     3 | r4 |    | r4     |   |   |    |   |
|     4 |    |    | r1     |   |   |    |   |
|     5 |    | s3 |        |   |   |    | 6 |
|     6 | s5 |    | r3     |   |   |  7 |   |
|     7 |    |    | r2     |   |   |    |   |

**** Trace: ~1 + 1~

| step | stack                      | input   | action |
|------+----------------------------+---------+--------|
|    1 | 0,                         | 1 + 1 $ | s3     |
|    2 | 0, 1, 3                    | + 1 $   | r4     |
|    3 | 0, T                       | + 1 $   | 2      |
|    4 | 0, T, 2                    | + 1 $   | s5     |
|    5 | 0, T, 2, +, 5              | 1 $     | s3     |
|    6 | 0, T, 2, +, 5, 1, 3        | $       | r4     |
|    7 | 0, T, 2, +, 5, T           | $       | 6      |
|    8 | 0, T, 2, +, 5, T, 6        | $       | r3     |
|    9 | 0, T, 2, +, 5, T, 6, E'    | $       | 7      |
|   10 | 0, T, 2, +, 5, T, 6, E', 7 | $       | r2     |
|   11 | 0, T, 2, E'                | $       | 4      |
|   12 | 0, T, 2, E', 4             | $       | r1     |
|   13 | 0, E                       | $       | 1      |
|   14 | 0, E, 1                    | $       | accept |

** Grammar Classes

#+begin_example
LL(1) ⊂ SLR ⊂ LALR ⊂ LR(1) ⊂ CFG
#+end_example

- Context-Free Grammar :: Any grammar whose rules have the form *A -> α*. Requires a parse
  table and a stack to track parser state. An ambiguous CFG creates a non-deterministic finite
  automaton.

- LR(k) :: Performs bottom-up, left-right scan and right-most parse of the input, deciding what rule
  to apply next by examining the next *k* tokens. Requires a very large automaton, because the possible
  lookaheads are encoded into states.

- LALR :: A /Lookahead-LR/ parser created by constructing an *LR(1)* parser then merging all item sets
  that have the same core.

- SLR :: A /Simple-LR/ parser approximates an *LR(1)* parser by constructing an *LR(0)* state machine
  and then relying on the *FIRST* and *FOLLOW* sets to select which rule to apply.

- LL(k) :: Performs a top-down, left-right scan and left-most parse of the input, deciding what items
  to rule to apply next by examining the next *k* tokens. *LL(1)* parsers require a only table that
  is *O(nt)* where *t* is the number of tokens and *n* is the number of non-terminals.

** The Chomsky Hierarchy

| language class         | machine required        |
|------------------------+-------------------------|
| regular                | finite automata         |
| context free           | pushdown automata       |
| context sensitive      | linear bounded automata |
| recursively enumerable | Turing machine          |

- Regular Languages :: Languages described by regular expressions. Every regular expression corresponds
  to a finite automaton that can be implemented with a table and a single integer to represent the
  current state.

- Context Free Languages :: The meaning of a non-terminal is the same in all places where it appears.
  CFGs require pushdown automaton, which requires a finite automaton coupled with a stack. If the
  grammar is ambiguous, the automaton will be non-deterministic and therefore impractical.

- Context Sensitive Languages :: The meaning of a non-terminal is controlled by the context in which it
  appears. CSLs require a non-deterministic linear bounded automaton, which is bounded in memory
  consumption but not in execution time.

- Recursively Enumerable Languages :: The least restrictive set of languages, described by the rules
  *α → β* where *α* and *β* can be any combination of terminals and non-terminals. These languages
  can only be recognized by a full Turing machine.
