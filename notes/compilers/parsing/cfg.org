* Context Free Grammars

** Sources

| source                                          | author                  |
|-------------------------------------------------+-------------------------|
| *Introduction to Compilers and Language Design* | Douglas Thain           |
| *Formal Languages* and *Set Theory*             | Wikipedia               |
| *Basics of Compiler Design*                     | Torben Ægidius Mogensen |

** Definitions

In formal language theory, a context-free grammar is a formal grammar whose production rules
can be applied to a non-terminal symbol regardless of its context. The left-hand side of each
production rule is a single non-terminal. The right-hand side of each production rule is
a sentential form that describes the allowable forms of the corresponding non-terminal.

- terminal :: The elementary symbols of a language.

- non-terminal :: A language structure that can be replaced by sequences of terminal symbols.
  Also called syntactic variables.

- sentence :: A valid sequence of terminals.

- sentential form :: A valid sequence of terminals and non-terminals.

- grammar :: A finite set of rules describing a valid set of sentences.

- language :: The potentially infinite set of sentences described or set of strings generated
  by a particular grammar.

- start symbol :: The special, non-terminal symbol representing the top-level definition
  of a program.

- derivation :: A sequence of rule applications that prove a sentence is a member of a
  particular language.

- (⇒) :: Shows that one sentential form is equal to another by applying a given rule.

- top-down derivation :: Begins with the start symbol. Applies production rules, rewriting
  non-terminals to terminals until the desired sentence is reached.

- bottom-up derivation :: Begins with the desired sentence. Applies production rules,
  rewriting terminals to non-terminals until the start symbol is reached.

- weak equivalence :: Two separate grammars that generate the same language.

- production :: A rewrite rule specifying symbol substitution to generate new symbol sequences.

** RE to CFG

| RE          | CFG    |
|-------------+--------|
| ε           | I → ε  |
|-------------+--------|
| s           | I → s  |
|-------------+--------|
| st or s • t | I → st |
|-------------+--------|
| s\vert{}t   | I → s  |
|             | I → t  |
|-------------+--------|
| s*          | I → sI |
|             | I → ε  |
|-------------+--------|
| s+          | I → sI |
|             | I → s  |
|-------------+--------|
| s?          | I → s  |
|             | I → ε  |

- regular grammar :: A grammar that is either right or left regular and describes a regular language.

#+begin_example
  === right-regular grammar ===

  1. A → a
  2. A → aB
  3. A → ε

    A
   / \
  a   A
     / \
    a   ...

  === left-regular grammar ===

  1. A → a
  2. A → Ba
  3. A → ε

        A
       / \
      A   a
     / \
  ...   a
#+end_example

** Derivation

#+begin_quote
  "The basic idea of derivation is to consider productions as rewrite rules:
   Whenever we have a nonterminal, we can replace this by the right-hand side
   of any production in which the nonterminal appears on the left-hand side.
   We can do this anywhere in a sequence of symbols (terminals and nonterminals)
   and repeat doing so until we have only terminals left. The resulting sequence
   of terminals is a string in the language defined by the grammar."

  — *Basics of Compiler Design*, Torben Ægidius Mogensen
#+end_quote

1. *αNβ ⇒ αγβ* if there is a production *N → γ*

   - Using a production as a rewrite rule anywhere in a sequence of grammar symbols
     is a derivation step.

2. *α ⇒ α*

   - A derivation relation is reflexive. A sequence derives itself.

3. *α ⇒ γ* if there is a *β* such that *α ⇒ β* and *β ⇒ γ*

   - Transitive: A sequence of derivations is in itself a derivation.

| rule | production |
|------+------------|
|    1 | S → E      |
|    2 | E → E + E  |
|    3 | E → id     |
|    4 | E → 1      |

For brevity, we occasionally condense a set of rules with a common left-hand side by combining all
the right-hand sides with a logical-or symbol:

#+begin_example
  E → E + E
  E → id
  E → 1

  - equivalent ->

  E → E + E
    | id
    | 1
#+end_example

** Top-Down Derivation

| sentential form | apply rule |
|-----------------+------------|
| S               | S → E      |
| E               | E → E + E  |
| E + E           | E → id     |
| id + E + E      | E → 1      |
| id + 1 + E      | E → 1      |
| id + 1 + 1      |            |

** Bottom-Up Derivation

| sentential form | apply rule |
|-----------------+------------|
| id + 1 + 1      | E → 1      |
| id + 1 + E      | E → 1      |
| id + E + E      | E → E + E  |
| id + E          | E → id     |
| E + E           | E → E + E  |
| E               | S → E      |
| S               |            |

** Ambiguity

#+begin_quote
  "How do we know if a grammar is ambiguous? If we can find a string and show
   two alternative syntax trees for it, this is a proof of ambiguity. It may,
   however, be hard to find such a string and, when the grammar is unambiguous,
   even harder to show that this is the case. In fact, the problem is
   formally undecidable...

   Given two grammars, it would be nice to be able to tell if they are equivalent.
   Unfortunately, no known method is able to decide this in all cases, but, unlike
   ambiguity, it is not (at the time of writing) known if such a method may or may
   not theoretically exist. "

  — *Basics of Compiler Design*, Torben Ægidius Mogensen
#+end_quote

~id + 1 + 1~ for the grammar above is ambiguous because it has two possible derivations.

*** Left-Most Derivation

#+begin_example
        S
        |
        E
        |
      E + E
      /   \
   E + E   1
   /   \
 id     1
#+end_example

*** Right-Most Derivation

#+begin_example
      S
      |
      E
      |
    E + E
    /   \
  id   E + E
       /   \
      1     1
#+end_example

** Removing Ambiguity

It is possible to re-write a grammar so that it is not ambiguous. With binary operators,
we can require one side of an expression to be an atomic term (*T*). The grammar below
is no longer ambiguous, because it allows only a left-most derivation.

| rule | production |
|------+------------|
|    1 | S → E      |
|    2 | E → E + T  |
|    3 | E → T      |
|    4 | T → id     |
|    5 | T → 1      |

Further modification to the grammar is required to account for multiple levels of precedence.
The usual approach is to construct a grammar with multiple levels, each reflecting the
intended precedence of operators. Addition combined with multiplication can be expressed
as the sum of terms (*T*) that consist of multiplied factors (*F*).

#+begin_quote
  "We also need to handle operators with different precedences. This is done by
   using a nonterminal for each precedence level. The idea is that if an expression
   uses an operator of a certain precedence level, then its subexpressions cannot use
   operators of lower precedence (unless these are inside parentheses)."

  — *Basics of Compiler Design*, Torben Ægidius Mogensen
#+end_quote

| rule | production |
|------+------------|
|    1 | S → E      |
|    2 | E → E + T  |
|    3 | E → T      |
|    4 | T → T * F  |
|    5 | T → F      |
|    6 | F → id     |
|    7 | F → 1      |

#+begin_example
  === ambiguous ===

  E → E + E
    | E * E
    | ( E )
    | 1

  === unambiguous ===

  E → T
    | E + T

  T → F
    | T * F

  F → 1
    | ( E )
#+end_example
